Autonomous Research Agent
A production-grade autonomous research agent with safety guardrails, tool integration, and comprehensive observability.
ğŸ“ Repository Structure
autonomous-research-agent/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci.yml
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                    # FastAPI application
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ routes.py              # API endpoints
â”‚   â”‚   â””â”€â”€ models.py              # Pydantic models
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ agent.py               # Main agent logic
â”‚   â”‚   â”œâ”€â”€ planner.py             # Task planning strategies
â”‚   â”‚   â”œâ”€â”€ memory.py              # SQLite memory store
â”‚   â”‚   â””â”€â”€ guardrails.py          # Safety mechanisms
â”‚   â”œâ”€â”€ tools/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py                # Tool interface
â”‚   â”‚   â”œâ”€â”€ web_search.py          # DuckDuckGo search
â”‚   â”‚   â”œâ”€â”€ web_fetch.py           # Web content fetching
â”‚   â”‚   â”œâ”€â”€ calculator.py          # Math operations
â”‚   â”‚   â”œâ”€â”€ file_ops.py            # File read/write
â”‚   â”‚   â””â”€â”€ sql_query.py           # SQLite queries
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ adapters.py            # OpenAI/HF adapters
â”‚   â”‚   â””â”€â”€ prompts.py             # Prompt templates
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ security.py            # Security utilities
â”‚       â”œâ”€â”€ observability.py       # Logging/metrics
â”‚       â””â”€â”€ config.py              # Settings management
â”œâ”€â”€ cli/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ client.py                  # CLI interface
â”œâ”€â”€ ui/
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.js
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ TaskForm.js
â”‚   â”‚   â”‚   â””â”€â”€ TaskTrace.js
â”‚   â”‚   â””â”€â”€ index.js
â”‚   â””â”€â”€ public/
â”‚       â””â”€â”€ index.html
â”œâ”€â”€ eval/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ benchmarks.py              # Synthetic benchmarks
â”‚   â”œâ”€â”€ scoring.py                 # Evaluation metrics
â”‚   â””â”€â”€ tasks/
â”‚       â”œâ”€â”€ fact_collection.py
â”‚       â””â”€â”€ web_research.py
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py                # Pytest fixtures
â”‚   â”œâ”€â”€ test_agent.py
â”‚   â”œâ”€â”€ test_tools.py
â”‚   â”œâ”€â”€ test_api.py
â”‚   â””â”€â”€ test_security.py
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ THREAT_MODEL.md
â”‚   â”œâ”€â”€ SAFETY_GUIDELINES.md
â”‚   â””â”€â”€ diagrams/
â”‚       â”œâ”€â”€ agent_loop.mmd
â”‚       â””â”€â”€ tool_calls.mmd
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup.sh
â”‚   â””â”€â”€ demo.py
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .pre-commit-config.yaml
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ LICENSE
â”œâ”€â”€ Makefile
â”œâ”€â”€ pyproject.toml
â””â”€â”€ README.md
ğŸš€ Quick Start
bash# Setup
make setup

# Run development server
make run

# Run demo
make demo

# Run tests
make test
ğŸ”§ Configuration
Copy .env.example to .env and configure:
bash# LLM Configuration
OPENAI_API_KEY=your_key_here
LLM_PROVIDER=openai
MODEL_NAME=gpt-4-turbo-preview

# Safety Settings
SAFE_MODE=true
MAX_STEPS=10
TIMEOUT_SECONDS=300
RATE_LIMIT_REQUESTS=100
RATE_LIMIT_WINDOW=3600

# Database
DATABASE_URL=sqlite:///./agent_memory.db

# Observability
LOG_LEVEL=INFO
ENABLE_METRICS=true
ENABLE_TRACING=true
ğŸ›¡ï¸ Safety Features

Guardrails: URL allowlists, prompt injection detection
Sandboxing: File operations restricted to safe directories
Rate Limiting: Configurable per-tool limits
Timeouts: Maximum execution time per task
PII Redaction: Automatic scrubbing of sensitive data

ğŸ“Š Observability

Structured Logging: JSON logs with trace correlation
Metrics: Prometheus-compatible metrics
Tracing: OpenTelemetry distributed tracing
Health Checks: Endpoint monitoring

ğŸ¯ Evaluation
Built-in evaluation framework with:

Synthetic benchmarks
Golden answer comparisons
Performance metrics (latency, accuracy, step count)
Automated scoring

ğŸ¤ Contributing

Install pre-commit hooks: pre-commit install
Run tests: make test
Follow conventional commits
Ensure 100% type coverage with mypy

ğŸ“œ License
MIT License - see LICENSE file.
